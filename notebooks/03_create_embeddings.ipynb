{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5195a7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9027f0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data:\n",
      "  Train: 1790 users\n",
      "  Val: 384 users\n",
      "  Test: 384 users\n",
      "\n",
      "Labels: ['ADHD', 'OCD', 'aspergers', 'depression', 'ptsd']\n"
     ]
    }
   ],
   "source": [
    "# Load the data we saved\n",
    "with open('../data/processed_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train = data['X_train']\n",
    "X_val = data['X_val']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_val = data['y_val']\n",
    "y_test = data['y_test']\n",
    "label_encoder = data['label_encoder']\n",
    "\n",
    "print(f\"Loaded data:\")\n",
    "print(f\"  Train: {len(X_train)} users\")\n",
    "print(f\"  Val: {len(X_val)} users\")\n",
    "print(f\"  Test: {len(X_test)} users\")\n",
    "print()\n",
    "print(f\"Labels: {label_encoder.classes_.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b33f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rutujashingate/Desktop/mental-heatlh-detection/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SBERT model: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5099511fa29c4bd989aef4cbbc31a999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08885df0737a48c4b1e6e167e2f33e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef62861215f641beac22cc2c66273a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7c4286278f4ce694d75663400aa2a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851ce50534c242c484447cd8081af3e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c29988fab0d47baada04a2c56422cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2aab3dfa8824f708f1a3e1155ad561a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f66b6bfd6e14b858a02ff2dc169e8fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309a2851823d477cb584295951371963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2898ac06a6014bac8b8061ff86bffa27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2496ed9ba7594a4d85e0f811f048f5c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded!\n",
      "Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a lightweight but effective model\n",
    "\n",
    "model_name = 'all-MiniLM-L6-v2'  \n",
    "\n",
    "print(f\"Loading SBERT model: {model_name}\")\n",
    "sbert_model = SentenceTransformer(model_name)\n",
    "print(\"✓ Model loaded!\")\n",
    "\n",
    "# Check embedding dimension\n",
    "test_embedding = sbert_model.encode(\"test sentence\")\n",
    "print(f\"Embedding dimension: {len(test_embedding)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16ce2d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample timeline: 6 posts\n",
      "Embedding shape: (6, 384)\n",
      "  - 6 posts\n",
      "  - 384 dimensions per post\n"
     ]
    }
   ],
   "source": [
    "def embed_timeline(timeline, model):\n",
    "    \"\"\"\n",
    "    Convert a user's timeline (list of posts) into embeddings.\n",
    "    \n",
    "    Args:\n",
    "        timeline: List of post texts\n",
    "        model: SBERT model\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of shape (num_posts, embedding_dim)\n",
    "    \"\"\"\n",
    "    embeddings = model.encode(timeline, show_progress_bar=False)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Test it\n",
    "sample_timeline = X_train[0]\n",
    "sample_embedding = embed_timeline(sample_timeline, sbert_model)\n",
    "\n",
    "print(f\"Sample timeline: {len(sample_timeline)} posts\")\n",
    "print(f\"Embedding shape: {sample_embedding.shape}\")\n",
    "print(f\"  - {sample_embedding.shape[0]} posts\")\n",
    "print(f\"  - {sample_embedding.shape[1]} dimensions per post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b940b1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding training timelines...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding timelines: 100%|██████████| 1790/1790 [02:24<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding validation timelines...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding timelines: 100%|██████████| 384/384 [00:34<00:00, 11.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding test timelines...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding timelines: 100%|██████████| 384/384 [00:31<00:00, 12.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ All embeddings created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def embed_all_timelines(timelines, model):\n",
    "    \"\"\"Embed all timelines with progress bar\"\"\"\n",
    "    embeddings = []\n",
    "    for timeline in tqdm(timelines, desc=\"Embedding timelines\"):\n",
    "        emb = embed_timeline(timeline, model)\n",
    "        embeddings.append(emb)\n",
    "    return embeddings\n",
    "\n",
    "print(\"Embedding training timelines...\")\n",
    "X_train_emb = embed_all_timelines(X_train, sbert_model)\n",
    "\n",
    "print(\"\\nEmbedding validation timelines...\")\n",
    "X_val_emb = embed_all_timelines(X_val, sbert_model)\n",
    "\n",
    "print(\"\\nEmbedding test timelines...\")\n",
    "X_test_emb = embed_all_timelines(X_test, sbert_model)\n",
    "\n",
    "print(\"\\n✓ All embeddings created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dff2f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding statistics:\n",
      "\n",
      "Train set:\n",
      "  Users: 1790\n",
      "  Timeline lengths: min=5, max=50, mean=9.4\n",
      "  Embedding dim: 384\n",
      "\n",
      "Sample embedding (first user, first post):\n",
      "  Shape: (384,)\n",
      "  Values: [-0.00834035 -0.0725477   0.03805013  0.08869714  0.04437679]...\n"
     ]
    }
   ],
   "source": [
    "print(\"Embedding statistics:\")\n",
    "print()\n",
    "print(\"Train set:\")\n",
    "train_lengths = [emb.shape[0] for emb in X_train_emb]\n",
    "print(f\"  Users: {len(X_train_emb)}\")\n",
    "print(f\"  Timeline lengths: min={min(train_lengths)}, max={max(train_lengths)}, mean={np.mean(train_lengths):.1f}\")\n",
    "print(f\"  Embedding dim: {X_train_emb[0].shape[1]}\")\n",
    "\n",
    "print()\n",
    "print(\"Sample embedding (first user, first post):\")\n",
    "print(f\"  Shape: {X_train_emb[0][0].shape}\")\n",
    "print(f\"  Values: {X_train_emb[0][0][:5]}...\")  # First 5 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aa3cd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved to data/embeddings.pkl\n",
      "\n",
      "File contains:\n",
      "  X_train_emb: 1790 items\n",
      "  X_val_emb: 384 items\n",
      "  X_test_emb: 384 items\n",
      "  y_train: array shape (1790,)\n",
      "  y_val: array shape (384,)\n",
      "  y_test: array shape (384,)\n",
      "  label_encoder: LabelEncoder()\n",
      "  embedding_dim: 384\n",
      "  model_name: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "# Save embeddings\n",
    "embeddings_data = {\n",
    "    'X_train_emb': X_train_emb,\n",
    "    'X_val_emb': X_val_emb,\n",
    "    'X_test_emb': X_test_emb,\n",
    "    'y_train': y_train,\n",
    "    'y_val': y_val,\n",
    "    'y_test': y_test,\n",
    "    'label_encoder': label_encoder,\n",
    "    'embedding_dim': X_train_emb[0].shape[1],\n",
    "    'model_name': model_name\n",
    "}\n",
    "\n",
    "with open('../data/embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings_data, f)\n",
    "\n",
    "print(\"✓ Saved to data/embeddings.pkl\")\n",
    "print()\n",
    "print(\"File contains:\")\n",
    "for key, value in embeddings_data.items():\n",
    "    if isinstance(value, list):\n",
    "        print(f\"  {key}: {len(value)} items\")\n",
    "    elif isinstance(value, np.ndarray):\n",
    "        print(f\"  {key}: array shape {value.shape}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88a573e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
